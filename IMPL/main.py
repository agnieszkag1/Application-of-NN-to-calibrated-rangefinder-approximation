import csv
import itertools
import numpy as np
import plotly.graph_objects as go
import pandas as pd
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split


# mini_lidar_s is a
# leica is b
def model_calculating(a, b):
    # Data conversion to numpy matrix
    x = np.array(a).reshape(-1, 1)
    y = np.array(b).reshape(-1, 1)

    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)

    # Creating and training neuron network model
    # two models with different layout of hidden layers differenting in
    model1 = MLPRegressor(hidden_layer_sizes=(100, 90, 80, 70, 60, 50, 40, 30, 20, 10,), max_iter=10000,
                          random_state=42)
    model2 = MLPRegressor(hidden_layer_sizes=(100, 50, 10,), max_iter=10000, random_state=42)
    model1.fit(xtrain, ytrain.ravel())
    model2.fit(xtrain, ytrain.ravel())

    # Calculating measurement error based on
    # average value of absolute differences
    # between Leika reference measurements and
    # predicted by neuron network model for MiniLidarS measurements
    y_pred = model1.predict(xtest)
    error = mean_squared_error(ytest, y_pred)

    # Printing of mean square error calculated based on all predicts of values and Leika reference values as percentage
    print("Mean square error 1: {:.6f}".format(error))

    # Calculating measurement error based on
    # average value of absolute differences
    # between Leika reference measurements and
    # predicted by neuron network model for MiniLidarS measurements
    y_pred = model2.predict(xtest)
    error = mean_squared_error(ytest, y_pred)

    # Printing of mean square error calculated based on all predicts of values and Leika reference values as percentage
    print("Mean square error 2: {:.6f}".format(error))

    # Printing value of score as percentage function from model using dataset
    y_pred = np.array(y_pred).reshape(-1, 1)
    score = model1.score(y_pred, xtest)
    nscore = score * 100
    print("Score 1:{:.4f}%".format(nscore))

    # Printing value of score as percentage function from model using dataset
    y_pred = np.array(y_pred).reshape(-1, 1)
    score = model2.score(y_pred, xtest)
    nscore = score * 100
    print("Score 2:{:.4f}%".format(nscore))

    # array and variables for calculating data needed for plots
    newdatay = []
    newdatax = []
    prevy = y[0][0]
    tmpx = []

    for i in range(len(y)):
        if y[i][0] != prevy:
            newdatax.append(tmpx)
            newdatay.append(prevy)
            tmpx = []
        prevy = y[i][0]
        tmpx.append(x[i][0])

    newdatax.append(tmpx)
    newdatay.append(prevy)

    df = pd.DataFrame()

    # arrays of minimal and maximal values used for plot
    mintab = []
    maxtab = []

    for i in range(len(newdatax)):
        mintab.append(min(newdatax[i]))
        maxtab.append(max(newdatax[i]))

    df['Value'] = newdatay
    df['Min'] = mintab
    df['Max'] = maxtab
    # predicts using model based on average value of min and max for plot
    predicts1 = []
    predicts2 = []
    avgvalues = []
    for i in range(len(mintab)):
        avgvalue = (mintab[i] + maxtab[i]) / 2
        avgvalues.append(avgvalue)
        predict = model1.predict([[avgvalue]])
        predicts1.append(predict[0])
        predict = model2.predict([[avgvalue]])
        predicts2.append(predict[0])

    df2 = pd.DataFrame()
    df2['Value'] = predicts1
    df2['Line'] = avgvalues

    df3 = pd.DataFrame()
    df3['Value'] = predicts2
    df3['Line'] = avgvalues

    # creating plots to show current dataset used for training and predicts of that trained model
    trace0 = go.Scatter(x=df['Value'], y=df['Value'], mode='lines', line=dict(color='green'),
                        name="ideal value")
    trace1 = go.Candlestick(x=df['Value'], open=df['Min'], high=df['Max'], low=df['Min'], close=df['Max'],
                            name="data set")
    trace2 = go.Scatter(x=df2['Value'], y=df2['Line'], mode='lines', line=dict(color='red'),
                        name="Line generated by model 1")
    trace3 = go.Scatter(x=df3['Value'], y=df3['Line'], mode='lines', line=dict(color='blue'),
                        name="Line generated by model 2")
    data = [trace0, trace1, trace2, trace3]
    fig = go.Figure(data)
    fig.update_layout(title="Plot of data", xaxis_title="Leica value", yaxis_title="Minilidar value", width=1000,
                      height=1000)

    # show those plots together in web browser
    fig.show()
    leicavalues = []
    minilidarsvalues = []
    resultvalues = []
    jumpsize = len(x) / 8
    for i in range(8):
        jump = int(i * jumpsize)
        leica = y[jump]
        minilidars = x[jump]
        result = model1.predict([minilidars])
        leicavalues.append(leica[0])
        minilidarsvalues.append(minilidars[0])
        resultvalues.append(float("{:.3f}".format(result[0])))
    print("Leica values:")
    print(leicavalues)
    print("MinilidarS values:")
    print(minilidarsvalues)
    print("Model result values:")
    print(resultvalues)
    print()
    return model1
    # END OF model_calculating


def defaultvalues():
    print("Default values:")
    # Input data from .csv file proviced by instructor
    with open("DFRobot_MiniS.csv", "r") as file:
        data = list(csv.reader(file, delimiter=","))
    leica = []
    mini_lidar_s = []

    # Skip headers from .csv while inputing data
    for item in data[1:]:
        leica.append(float(item[0]))
        mini_lidar_s.append(float(item[1]))

    # Calculating and training model using this dataset
    return model_calculating(mini_lidar_s, leica)
    # END OF defaultvalues


def first5values():
    print("First 5 values:")
    # Input data from .csv file proviced by instructor
    with open("DFRobot_MiniS.csv", "r") as file:
        data = list(csv.reader(file, delimiter=","))

    leica = []
    mini_lidar_s = []

    # Skip headers from .csv while inputting data
    for item in data[1:]:
        current_measurement = float(item[0])
        if leica.count(current_measurement) < 5:
            leica.append(current_measurement)
            mini_lidar_s.append(float(item[1]))

    # Calculating and training model using this dataset
    return model_calculating(mini_lidar_s, leica)
    # END OF first5values


def closest5values():
    print("Closest 5 values:")
    # Input data from .csv file proviced by instructor
    with open("DFRobot_MiniS.csv", "r") as file:
        data = list(csv.reader(file, delimiter=","))

    leica_data = {}

    # Skip headers from .csv while inputting data
    for item in data[1:]:
        current_measurement = float(item[0])
        current_value = float(item[1])

        if current_measurement not in leica_data:
            leica_data[current_measurement] = []

        leica_data[current_measurement].append(current_value)

    # Select the five most similar values for each leica measurement
    selected_values = []
    for measurement, values in leica_data.items():
        sorted_values = sorted(values)
        most_similar = sorted_values[:5]
        selected_values.extend(most_similar)

    # Split selected values into leica and mini_lidar_s lists
    leica = [measurement for measurement, _ in itertools.groupby(leica_data) for _ in range(5)]
    mini_lidar_s = selected_values[:len(leica)]

    # Calculating and training model using this dataset
    return model_calculating(mini_lidar_s, leica)
    # END OF closest5values


def sortedvaluesasc():
    print("Sorted values asc:")
    # Input data from .csv file proviced by instructor
    with open("DFRobot_MiniS.csv", "r") as file:
        data = list(csv.reader(file, delimiter=","))

    leica = []
    mini_lidar_s = []

    # Skip headers from .csv while inputting data
    for item in data[1:]:
        leica.append(float(item[0]))
        mini_lidar_s.append(float(item[1]))

    # Sort the data based on leica
    sorted_data = sorted(zip(leica, mini_lidar_s))

    # Unzip the sorted data
    leica_sorted, mini_lidar_s_sorted = zip(*sorted_data)

    # Calculating and training model using this dataset
    return model_calculating(mini_lidar_s_sorted, leica_sorted)
    # END OF sortedvaluesasc


def sortedvaluesdesc():
    print("Sorted values desc:")
    # Input data from .csv file proviced by instructor
    with open("DFRobot_MiniS.csv", "r") as file:
        data = list(csv.reader(file, delimiter=","))

    leica = []
    mini_lidar_s = []

    # Skip headers from .csv while inputting data
    for item in data[1:]:
        leica.append(float(item[0]))
        mini_lidar_s.append(float(item[1]))

    # Sort the data based on leica
    sorted_data = sorted(zip(leica, mini_lidar_s), reverse=True)

    # Unzip the sorted data
    leica_sorted, mini_lidar_s_sorted = zip(*sorted_data)

    # Calculating and training model using this dataset
    return model_calculating(mini_lidar_s_sorted, leica_sorted)
    # END OF sortedvaluesasc


def usemodel(models_to_use):
    while True:
        print("0. End program")
        print("1. Choose model 1")
        print("2. Choose model 2")
        print("3. Choose model 3")
        print("4. Choose model 4")
        print("5. Choose model 5")
        whichModel = input()
        if whichModel == '0':
            break
        print("Input value from MinilidaraS:")
        value = input()
        try:
            value = float(value)
            value = [[value]]
            print("Computed value using model is:")
            result = []
            if whichModel == '1':
                result = models_to_use[0].predict(value)
            if whichModel == '2':
                result = models_to_use[1].predict(value)
            if whichModel == '3':
                result = models_to_use[2].predict(value)
            if whichModel == '4':
                result = models_to_use[3].predict(value)
            if whichModel == '5':
                result = models_to_use[4].predict(value)
            print(float("{:.3f}".format(result[0])))
        except:
            print("Value must be float number")


# MAIN CODE
models = [defaultvalues(), first5values(), closest5values(), sortedvaluesasc(), sortedvaluesdesc()]
usemodel(models)
